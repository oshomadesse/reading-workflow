# -*- coding: utf-8 -*-
import os, json, re, datetime, unicodedata
from pathlib import Path
from urllib.parse import quote
from dotenv import load_dotenv

PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(PROJECT_DIR, "data")
INF_DIR  = os.path.join(PROJECT_DIR, "infographics")  # ãƒ†ãƒ³ãƒ—ãƒ¬é…ç½®ç”¨ã«å­˜ç¶š
TPL_PATH = os.path.join(INF_DIR, "infographic_template.html")

# â˜… Vault ãƒ«ãƒ¼ãƒˆã¨ 100_Inboxï¼ˆHTMLã®ä¿å­˜å…ˆï¼‰
if os.getenv("GITHUB_ACTIONS"):
    VAULT_ROOT = Path(PROJECT_DIR).resolve()
    INBOX_DIR = VAULT_ROOT / "100_Inbox"
else:
    VAULT_ROOT = Path(os.getenv("VAULT_ROOT", "/Users/seihoushouba/Documents/Oshomadesse-pc")).resolve()
    INBOX_DIR  = Path(os.getenv("INBOX_DIR", str(VAULT_ROOT / "100_Inbox"))).resolve()

for d in (DATA_DIR, INF_DIR, INBOX_DIR):
    os.makedirs(d, exist_ok=True)
load_dotenv(os.path.join(PROJECT_DIR, ".env"))

try:
    from anthropic import Anthropic
except Exception as e:
    raise RuntimeError("anthropic ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™: pip install anthropic") from e

API_KEY = os.getenv("ANTHROPIC_API_KEY")
if not API_KEY:
    raise ValueError("ANTHROPIC_API_KEY ãŒæœªè¨­å®šã§ã™")

MODEL       = os.getenv("ANTHROPIC_MODEL", "claude-sonnet-4-5-20250929")
MAX_TOKENS  = int(os.getenv("ANTHROPIC_MAX_TOKENS", "16384"))
TEMPERATURE = float(os.getenv("ANTHROPIC_TEMPERATURE", "0"))  # æ±ºå®šè«–å¯„ã›
client = Anthropic(api_key=API_KEY)

def _slug(s, n=80):
    if not s:
        s = "infographic"
    s = unicodedata.normalize("NFKC", str(s))
    s = re.sub(r"\s+", "_", s)
    s = re.sub(r"[^\w\-]", "_", s)
    s = re.sub(r"_+", "_", s).strip("_")
    return (s[:n] or "infographic")

def _atomic_write(path, text):
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    tmp = p.parent / (".tmp." + p.name)
    tmp.write_text(text, encoding="utf-8")
    tmp.replace(p)

def _latest_nonempty_raw():
    pdir = Path(DATA_DIR)
    if not pdir.exists():
        return (None, "")
    raws = sorted(pdir.glob("deep*raw.txt"), key=lambda p: p.stat().st_mtime, reverse=True)
    ts_pattern = re.compile(r"^deep_.+_\d{8}_\d{6}__raw\.txt$")
    ts_candidates = [p for p in raws if ts_pattern.match(p.name)]
    search_list = ts_candidates + [p for p in raws if p not in ts_candidates]
    for p in search_list:
        try:
            t = p.read_text(encoding="utf-8")
        except Exception:
            continue
        if t and t.strip():
            return p, t
    return (None, "")

def _coerce_deep_text(deep, title_hint=""):
    if isinstance(deep, dict):
        for k in ("raw","fulltext","text","body","overview"):
            v = deep.get(k)
            if isinstance(v, (str, bytes)) and str(v).strip():
                s = str(v)
                print("ğŸ” deep provided via dict (key:", k, ") (len=", len(s), "chars )")
                return s
        try:
            s = json.dumps(deep, ensure_ascii=False, indent=2)
            if s and s.strip():
                print("ğŸ” deep provided as dict -> json-serialized (len=", len(s), "chars )")
                return s
        except Exception:
            pass

    if isinstance(deep, (str, bytes)) and str(deep).strip():
        s = str(deep)
        print("ğŸ” deep provided directly (len=", len(s), "chars )")
        return s

    p, t = _latest_nonempty_raw()
    if p:
        print(f"ğŸ” deep/raw æ¢ç´¢: {p} ({len(t)} chars)")
    if t and t.strip():
        return t

    if title_hint:
        return str(title_hint)
    return ""

def _read_template():
    try:
        return Path(TPL_PATH).read_text(encoding="utf-8")
    except Exception:
        print(f"âš  ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæœªèª­è¾¼: {TPL_PATH}")
        return ""

def _extract_meta_from_text(text: str):
    meta = {"title":"", "author":"", "category":""}
    try:
        obj = json.loads(text)
        for k in ("æ›¸ç±å","ã‚¿ã‚¤ãƒˆãƒ«","title"):
            if k in obj and isinstance(obj[k], str):
                meta["title"] = obj[k]
                break
        for k in ("è‘—è€…å","è‘—è€…","author","authors"):
            if k in obj:
                v = obj[k]
                meta["author"] = v if isinstance(v,str) else (", ".join(v) if isinstance(v,list) else str(v))
                break
    except Exception:
        pass
    if not meta["title"]:
        m = re.search(r'"(?:æ›¸ç±å|ã‚¿ã‚¤ãƒˆãƒ«|title)"\s*:\s*"([^"]+)"', text)
        if m:
            meta["title"] = m.group(1).strip()
    if not meta["author"]:
        m = re.search(r'"(?:è‘—è€…å|è‘—è€…|author)"\s*:\s*"([^"]+)"', text)
        if m:
            meta["author"] = m.group(1).strip()
    return meta

def _prefill_template(template_html: str, meta: dict):
    html = template_html
    repl = {
        "ã€æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã€‘": meta.get("title") or "ä¸æ˜",
        "ã€è‘—è€…åã€‘": meta.get("author") or "ä¸æ˜",
        "ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€‘": meta.get("category") or "ä¸æ˜",
    }
    for k,v in repl.items():
        html = html.replace(k, v)
    return html

def _build_user_text(deep_text, book_title):
    template_html = _read_template()
    if template_html:
        meta = _extract_meta_from_text(deep_text)
        if not meta["title"] and book_title:
            meta["title"] = book_title
        # ãƒ†ãƒ³ãƒ—ãƒ¬ã®äº‹å‰æ•´å½¢ã¯ç¾çŠ¶ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯æœªåŸ‹ã‚è¾¼ã¿ï¼ˆå°†æ¥æ‹¡å¼µç”¨ï¼‰
        _prefill_template(template_html, meta)

    content_block = f"\n=== ä»¥ä¸‹ã®å†…å®¹ ===\n{deep_text}\n=== ä»¥ä¸Š ===\n"

    prompt = """ã€InfographicæŒ‡ç¤ºï¼ˆæœ€çµ‚ç‰ˆï¼‰ã€‘
ã‚ãªãŸã¯è¦–è¦šåŒ–ã®ãƒ—ãƒ­ã®ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼å…¼ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…è€…ã§ã™ã€‚ä»¥ä¸‹ã®å¿…é ˆè¦ä»¶ã«å¾“ã£ã¦ã€æ›¸ç±ãƒªã‚µãƒ¼ãƒã®å†…å®¹ã‚’ã™ã¹ã¦èª­ã¿è¾¼ã¿ã€æ›¸ç±ã‚’ã€Œæœ¬ã‚’èª­ã‚“ã§ã„ãªã„äººã§ã‚‚å…¨ä½“åƒãŒæ´ã‚ã‚‹ã€å˜ä¸€HTMLã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚å‡ºåŠ›ã¯å˜ä¸€ã®å®Œçµã—ãŸHTMLï¼ˆå†…éƒ¨ã« CSS ã¨ JavaScript ã‚’å«ã‚€ï¼‰ã ã‘ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ãƒ»æ³¨é‡ˆãƒ»ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã¯ç¦æ­¢ã—ã¾ã™ã€‚


ã‚¿ãƒ–æ§‹æˆï¼ˆå›ºå®šï¼‰ï¼š
  - ä¸»è¦æ¦‚å¿µã®è©³ç´°ï¼šç´°ã‹ãã€åˆè¦‹ã§ã‚‚ç†è§£ã§ãã‚‹ã‚ˆã†å™›ã¿ç •ã„ãŸèª¬æ˜ã‚’ã‚«ãƒ¼ãƒ‰å½¢å¼ã§æ•´ç†ã—ã€å„æ¦‚å¿µã«ã¤ã„ã¦ã€Œç†ç”±ï¼ˆãªãœé‡è¦ã‹ï¼‰ã€ã‚’æ˜ç¤ºã™ã‚‹ã€‚
  - å„ç« ã®è¦ç´„ï¼šå„ç« ã®ãƒã‚¤ãƒ³ãƒˆã‚’çŸ­ã„è¦‹å‡ºã—ï¼‹ç®‡æ¡ã§ã¾ã¨ã‚ã€ç« ã”ã¨ã«ã€Œç†ç”±ï¼ˆãªãœãã®ç« ãŒå¿…è¦ã‹ï¼ç« ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ ¹æ‹ ï¼‰ã€ã‚’ä»˜ã™ã€‚ç« ç«‹ã¦ãŒä¸æ˜ãªå ´åˆã¯è«–ç‚¹ã”ã¨ã®ç–‘ä¼¼ç« ã‚’ä½œã‚‹ã€‚
  - å…·ä½“ä¾‹ï¼šæ ¸å¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒä¼ã‚ã‚‹å®Ÿéš›ã®ã‚±ãƒ¼ã‚¹ã‚„ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ã‚’å°‘ãªãã¨ã‚‚3ä»¶æç¤ºã—ã€èƒŒæ™¯ãƒ»ç¤ºå”†ã«åŠ ãˆã¦ã€Œç†ç”±ï¼ˆã“ã®ä¾‹ãŒç¤ºã™ã“ã¨ï¼‰ã€ã‚’å¿…ãšæ›¸ãã€‚
  - é‡è¦ãªå¼•ç”¨ï¼šåŸå…¸ã®é‡è¦ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’é¸ã³ã€å¼•ç”¨æ–‡ï¼‹ä¸€è¨€è£œè¶³ã§ä¸¦ã¹ã‚‹ï¼ˆå¼•ç”¨ãŒãªã„å ´åˆã¯è¦æ—¨ã§ä»£æ›¿ã—â€œè¦æ—¨â€ã¨æ˜è¨˜ï¼‰ã€‚
  - ä»Šæ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼š15ã€œ30åˆ†ã§å®Ÿè¡Œã§ãã‚‹å…·ä½“çš„ãªè¡Œå‹•ã‚’æœ€ä½3ã¤æç¤ºã—ã€ãã‚Œãã‚Œç›®çš„ã¨æœŸå¾…åŠ¹æœã‚’ä»˜ã™ã€‚

å¿…é ˆè¦ä»¶ï¼š
	1. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ãƒ†ã‚­ã‚¹ãƒˆ
	   - ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚¿ãƒ–ï¼ã‚«ãƒ¼ãƒ‰ï¼åˆ—ã§åˆ†å‰²ã™ã‚‹ã“ã¨ã€‚å„ã‚«ãƒ¼ãƒ‰ã¯ã€Œè¦‹å‡ºã—ï¼ˆ1è¡Œï¼‰ã€ï¼‹ã€Œè¦ç‚¹ç®‡æ¡ï¼ˆ3ã€œ5è¡Œï¼‰ã€ã«ã¾ã¨ã‚ã€å¿…è¦ã«å¿œã˜ã¦çµµæ–‡å­—ã‚„è¦ç‚¹ã”ã¨ã«çŸ­ã„èª¬æ˜ï¼ˆå„1è¡Œç¨‹åº¦ï¼‰ã‚’æ·»ãˆã¦å’€åš¼ã‚’åŠ©ã‘ã‚‹ã“ã¨ã€‚ é•·æ–‡ã®æ®µè½ã¯ç¦æ­¢ã€‚
	   - ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼ã«ã€Œè¦ç´„=å•ã„Ã—ç­”ãˆÃ—æ ¹æ‹ ï¼ˆWhyï¼ãªãœãã†ãªã®ã‹ï¼Ÿ&How=ãã®ãŸã‚ã«ã¯ï¼Ÿï¼‰ã€ã‚’æ˜ç¤ºã™ã‚‹å°‚ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã‚’é…ç½®ã—ã€1ãƒ–ãƒ­ãƒƒã‚¯å†…ã«å•ã„ãƒ»ç­”ãˆãƒ»Whyãƒ»Howã‚’çŸ­ãè¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
	2. æ•°å€¤ã¨æŒ‡æ¨™
	   - é‡è¦ãªæ•°å­—ãƒ»æŒ‡æ¨™ã¯è¦–è¦šåŒ–ï¼ˆæ¨ªæ£’ï¼å††ã‚°ãƒ©ãƒ•ï¼æ•°å€¤ãƒãƒƒã‚¸ç­‰ï¼‰ã§è¡¨ç¾ã—ã€çŸ­ã„ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã™ã“ã¨ã€‚
	3. ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
	   - ä½¿ç”¨ã™ã‚‹è‰²ã¯ã€Œãƒ—ãƒ©ã‚¤ãƒãƒªãƒ¼ / ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ¼ / ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã€ã®3è‰²ã¨ã—ã€3è‰²ã®ã†ã¡ã§ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä½¿ç”¨ã¯å¯ã€‚ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼š#667eeaï¼‰ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦HTMLå†…ã«å«ã‚ã‚‹ã“ã¨ã€‚
	4. ç¶²ç¾…æ€§ã¨è¦–è¦šåŒ–
	   - ä¸ãˆã‚‰ã‚ŒãŸãƒªã‚µãƒ¼ãƒå†…å®¹ã¯æŠœã‘ãªãåæ˜ ã™ã‚‹ï¼ˆè¦ç´„ã¯å¯ï¼‰ã€‚ãƒ†ã‚­ã‚¹ãƒˆã®ç¾…åˆ—ã§çµ‚ã‚ã‚‰ã›ãšã€å›³ã‚„çµµæ–‡å­—ãªã©ã®è¦–è¦šè¦ç´ ã‚’å¤šç”¨ã—ã¦æƒ…å ±ã‚’ä¼ãˆã‚‹ã“ã¨ã€‚
	5. ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ï¼†ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£
	   - ã‚¹ãƒãƒ›è¡¨ç¤ºã‚’æœ€å„ªå…ˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–è¨­è¨ˆã¨ã™ã‚‹ã€‚ã‚¿ãƒ–åˆ‡æ›¿ã¯ JavaScript ã§å®Ÿè£…ã—ã€é©åˆ‡ãª `aria-` å±æ€§ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã€‚
	6. æŠ€è¡“çš„åˆ¶ç´„
	   - å¤–éƒ¨ CDN ã‚„å¤–éƒ¨ç”»åƒãƒªãƒ³ã‚¯ã¯ç¦æ­¢ï¼ˆå…¨ã¦ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã§å®Œçµï¼‰ã€‚å‡ºåŠ›ã¯ HTML/CSS/JavaScript ã®ã‚³ãƒ¼ãƒ‰ã®ã¿ã€‚æœ€çµ‚å‡ºåŠ›ã¯å…ˆé ­ã« `<!DOCTYPE html>`ã€æœ«å°¾ã« `</html>` ã‚’å«ã¿ã€ã‚¿ã‚°æ•´åˆï¼ˆæœªé–‰ã˜ã‚¿ã‚°ãªã—ï¼‰ã‚’ä¿è¨¼ã™ã‚‹ã“ã¨ã€‚

å‡ºåŠ›å½¢å¼ã®è£œè¶³ï¼š
- å˜ä¸€ã®è‡ªå·±å®Œçµ HTMLï¼ˆ`<style>` ã¨ `<script>` ã‚’å†…éƒ¨ã«å«ã‚€ï¼‰ã€‚
- å¿…é ˆã®è¦–è¦šè¦ç´ ï¼ˆSVG/HTML/CSSï¼‰ã‚’å°‘ãªãã¨ã‚‚1ã¤å«ã‚ã‚‹ã“ã¨ã€‚
- HTML å†…ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚„ãƒ¡ã‚¿é ˜åŸŸã«ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ©ã‚¤ãƒãƒªãƒ¼ï¼ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ¼ï¼ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼‰ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨ã€‚

=== æ›¸ç±ãƒªã‚µãƒ¼ãƒï¼ˆã“ã“ã«ç½®æ›ï¼‰ ===
"""
    return prompt + content_block

def _save_raw_resp(resp, ts):
    try:
        dbg = Path(DATA_DIR) / "modules" / "claude_infographic" / f"claude_resp_raw_{ts}.txt"
        dbg.parent.mkdir(parents=True, exist_ok=True)
        try:
            s = json.dumps(resp, ensure_ascii=False, default=lambda o: getattr(o, '__dict__', str(o)))
        except Exception:
            s = repr(resp)
        dbg.write_text(s, encoding="utf-8")
        print(f"ğŸ“ Claude raw response saved: {dbg}")
    except Exception as e:
        print("âš ï¸ failed to save raw resp:", e)

def _call_claude(user_text):
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    dbg_path = Path(DATA_DIR) / "modules" / "claude_infographic" / f"claude_prompt_{ts}.txt"
    dbg_path.parent.mkdir(parents=True, exist_ok=True)
    try:
        dbg_path.write_text(user_text, encoding="utf-8")
        print(f"ğŸ“ Claude user_text saved: {dbg_path}")
    except Exception:
        print(f"âš ï¸ prompt save failed: {dbg_path}")
    
    system_text = (
        "ã‚ãªãŸã¯ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç”Ÿæˆã®ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã§ã™ã€‚"
        "å‡ºåŠ›ã¯å˜ä¸€ã®å®Œçµã—ãŸHTMLæ–‡æ›¸ã®ã¿ã¨ã—ã€å…ˆé ­ã¯'<!DOCTYPE html>'ã€æœ«å°¾ã¯'</html>'ã§çµ‚ãˆã¦ãã ã•ã„ã€‚"
        "èª¬æ˜æ–‡ãƒ»æ³¨é‡ˆãƒ»ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã¯ä¸€åˆ‡å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"
        "ä¸ãˆã‚‰ã‚ŒãŸæœ¬æ–‡ã«æ˜ç¢ºã«ãªã„æƒ…å ±ã‚’å‹æ‰‹ã«è¿½åŠ ã›ãšã€æ›–æ˜§ãªç®‡æ‰€ã¯ã€Œä¸æ˜ã€ã¨è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚"
    )

    resp = client.messages.create(
        model=MODEL,
        max_tokens=MAX_TOKENS,
        temperature=TEMPERATURE,
        system=system_text,
        messages=[{"role":"user","content":user_text}],
    )

    try:
        _save_raw_resp(resp, ts)
    except Exception:
        pass

    out = ""
    try:
        for part in (getattr(resp, "content", []) or []):
            if getattr(part, "type", None) == "text":
                out += getattr(part, "text", "") or ""
            else:
                out += getattr(part, "text", "") or ""
    except Exception:
        pass

    if not out:
        out = getattr(resp, "text", "") or getattr(resp, "output_text", "") or ""
    if not out:
        out = repr(resp)

    return out, getattr(resp, "usage", None)

def _extract_fields_for_template(deep_text:str):
    fields = {}
    try:
        obj = json.loads(deep_text)
        fields["æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"] = obj.get("æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸") or obj.get("1) æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸") or obj.get("1)") or ""
        fields["ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼"] = obj.get("ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼") or obj.get("2) ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼") or ""
        concepts = obj.get("3) ä¸»è¦æ¦‚å¿µãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰") or obj.get("ä¸»è¦æ¦‚å¿µãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰") or []
        fields["æ¦‚å¿µ_list"] = concepts
    except Exception:
        fields["æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"] = deep_text[:1000]
        fields["ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼"] = deep_text[:1000]
        fields["æ¦‚å¿µ_list"] = []
    return fields

def _vault_relative(p: Path) -> str:
    try:
        return p.resolve().relative_to(VAULT_ROOT).as_posix()
    except Exception:
        return p.as_posix()

def _obsidian_uri_for(vault_rel_path: str) -> str:
    vault = os.getenv("OBSIDIAN_VAULT_NAME") or VAULT_ROOT.name
    return f"obsidian://open?vault={quote(vault, safe='')}&file={quote(vault_rel_path, safe='')}"

def _app_local_uri(vault_rel_path: str) -> str:
    """Obsidianã®å†…éƒ¨Webãƒ“ãƒ¥ãƒ¼ã«ç›´æ¥èª­ã¿è¾¼ã¾ã›ã‚‹ã‚¹ã‚­ãƒ¼ãƒ ã€‚iOSã§HTMLãŒâ€œã‚µã‚¤ãƒˆã®ã‚ˆã†ã«â€é–‹ãæƒ³å®š"""
    vault = os.getenv("OBSIDIAN_VAULT_NAME") or VAULT_ROOT.name
    return f"app://local/{quote(vault, safe='')}/{quote(vault_rel_path, safe='')}"

# æ—§ï¼šè¤‡æ•°ãƒªãƒ³ã‚¯è¿½è¨˜é–¢æ•°ï¼ˆäº’æ›ã®ãŸã‚æ®‹ç½®ãƒ»æœªä½¿ç”¨ï¼‰
def _write_infographic_note(vault_rel_path: str, ob_uri: str, app_uri: str):
    pass  # ä»Šå›ã¯ Web å…¬é–‹ãƒªãƒ³ã‚¯ã®ã¿ã‚’æ—¥æ¬¡ãƒãƒ¼ãƒˆã«è¨˜è¼‰ã™ã‚‹æ–¹é‡ã®ãŸã‚æœªä½¿ç”¨

# === GitHub Pages å…¬é–‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========================================
import shutil, subprocess, time
import requests

def _wait_until_http_200(url: str, timeout_sec: int = 180, interval_sec: float = 2.5) -> bool:
    """GitHub Pages ã®CDNä¼æ’­ãŒçµ‚ã‚ã‚Š 200 ã‚’è¿”ã™ã¾ã§å¾…æ©Ÿ"""
    deadline = time.time() + timeout_sec
    while time.time() < deadline:
        try:
            r = requests.head(url, allow_redirects=True, timeout=6)
            if r.status_code == 200:
                return True
            if r.status_code in (403, 404):
                r = requests.get(url, allow_redirects=True, timeout=6)
                if r.status_code == 200:
                    return True
        except Exception:
            pass
        time.sleep(interval_sec)
    return False

def _read_public_env():
    export_dir = os.getenv("PUBLIC_EXPORT_DIR", "").strip()
    base_url   = os.getenv("PUBLIC_BASE_URL", "").strip()
    auto_push  = os.getenv("PUBLIC_GIT_AUTO_PUSH", "0").strip() in ("1","true","True")
    branch     = os.getenv("PUBLIC_GIT_BRANCH", "main").strip() or "main"
    commit_tmpl= os.getenv("PUBLIC_GIT_COMMIT_MSG", "[pages] add {filename}")
    if base_url and not base_url.endswith("/"):
        base_url += "/"
    return export_dir, base_url, auto_push, branch, commit_tmpl

def _append_web_link_to_daily_note(local_html_path: str, public_url: str, title_text: str):
    # ä»•æ§˜å¤‰æ›´ï¼šæ—¥æ¬¡ãƒãƒ¼ãƒˆã¯ä½œã‚‰ãªã„ï¼ˆäº’æ›ã®ãŸã‚ç©ºå®Ÿè£…ã‚’ç¶­æŒï¼‰
    return

def _git_auto_push(export_dir: str, filename: str, branch: str, commit_tmpl: str) -> bool:
    try:
        rel_name = Path(filename).name
        cmds = [
            (["git", "add", "-f", rel_name], True),  # *.html ã‚’ .gitignore ã—ã¦ã„ã¦ã‚‚å¼·åˆ¶è¿½åŠ 
            (["git", "commit", "-m", commit_tmpl.format(filename=rel_name)], False),
            (["git", "push", "origin", branch], True),
        ]
        ok = True
        for args, noisy in cmds:
            proc = subprocess.run(args, cwd=export_dir, capture_output=True, text=True)
            if proc.returncode != 0:
                ok = False
                if noisy:
                    print(f"âš ï¸ git ã‚³ãƒãƒ³ãƒ‰å¤±æ•—: {' '.join(args)}\n{proc.stderr.strip()}")
        return ok
    except Exception as e:
        print(f"âš ï¸ git push ã«å¤±æ•—: {e}")
        return False

def _publish_to_github_pages(local_html_path: str, filename: str, vault_rel: str=None, file_url: str=None, title_for_note: str = "Open on Web"):
    """
    HTML ã‚’ GitHub Pages ã® docs ã¸ã‚³ãƒ”ãƒ¼ã—ã€å…¬é–‹URLã‚’è¿”ã™ã€‚
    å¿…é ˆ: PUBLIC_EXPORT_DIR, PUBLIC_BASE_URL
    ãƒãƒªã‚·ãƒ¼: export_dir/base_url ãŒæƒã£ã¦ã„ã‚Œã°ã€200å¿œç­”ç¢ºèªã«å¤±æ•—ã—ã¦ã‚‚ public_url ã‚’è¿”ã™ï¼ˆéå³æ ¼ï¼‰ã€‚
             å³æ ¼ãªå¾…æ©Ÿã¯ PUBLIC_PAGES_STRICT_200=1 ã§æœ‰åŠ¹åŒ–ã€‚
    """
    export_dir, base_url, auto_push, branch, commit_tmpl = _read_public_env()
    wait_timeout = int(os.getenv("PUBLIC_PAGES_WAIT_TIMEOUT", "180"))
    strict_200   = os.getenv("PUBLIC_PAGES_STRICT_200", "0").strip().lower() in ("1","true","yes")
    fallback_url = file_url or vault_rel

    if not export_dir or not base_url:
        print("âš ï¸ PUBLIC_EXPORT_DIR ã¾ãŸã¯ PUBLIC_BASE_URL ãŒæœªè¨­å®šã®ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
        return fallback_url, "warn_env_missing"

    try:
        os.makedirs(export_dir, exist_ok=True)
        dst_path = Path(export_dir) / Path(filename).name

        # ç”Ÿæˆå…ˆãŒæ—¢ã« export_dir ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼ä¸è¦ï¼ˆSameFileErrorå›é¿ï¼‰
        if Path(local_html_path).resolve() != dst_path.resolve():
            shutil.copyfile(local_html_path, dst_path)
        else:
            print("â„¹ï¸ local_html_path ã¯ export_dir ã¨åŒä¸€ã®ãŸã‚ã‚³ãƒ”ãƒ¼çœç•¥")

        public_url = base_url + quote(dst_path.name)

        if auto_push:
            # export_dir ãŒ Git ç®¡ç†ä¸‹ã‹ç¢ºèª
            proc = subprocess.run(["git","rev-parse","--is-inside-work-tree"], cwd=export_dir, capture_output=True, text=True)
            in_repo = (proc.returncode == 0 and proc.stdout.strip() == "true")
            if not in_repo:
                print("âš ï¸ export_dir ãŒ Git ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚public_url ã‚’è¿”ã—ã¾ã™ï¼ˆæœªãƒ—ãƒƒã‚·ãƒ¥ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰ã€‚")
                return public_url, "warn_no_repo"
            pushed = _git_auto_push(str(Path(export_dir).resolve()), dst_path.name, branch, commit_tmpl)
            if not pushed:
                print("âš ï¸ push å¤±æ•—ã€‚public_url ã‚’è¿”ã—ã¾ã™ï¼ˆCDNæœªåæ˜ ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰ã€‚")
                return public_url, "warn_push_failed"

        if strict_200:
            if _wait_until_http_200(public_url, timeout_sec=wait_timeout):
                print(f"âœ… GitHub Pages 200 ç¢ºèª: {public_url}")
                return public_url, None
            else:
                print(f"âš ï¸ 200å¿œç­”ã‚’å¾…ã¦ãšã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸãŒ public_url ã‚’è¿”ã—ã¾ã™: {public_url}")
                return public_url, "pending"

        # éå³æ ¼ãƒ¢ãƒ¼ãƒ‰: å³ public_url è¿”ã™
        print(f"â¡ï¸ GitHub Pages URLï¼ˆéå³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼‰: {public_url}")
        return public_url, None

    except Exception as e:
        print(f"âš ï¸ GitHub Pages å…¬é–‹å‡¦ç†ã§ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆpublic_urlã«ã§ããªã„ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ï¼š{e}")
        return fallback_url, "warn_publish_error"
# ============================================================================

def generate_infographic(deep, book_title):
    deep_text = _coerce_deep_text(deep, book_title)
    print(f"ğŸ§ª deep_text chars = {len(deep_text)}")
    user_text = _build_user_text(deep_text, book_title)
    html, _usage = _call_claude(user_text)
    return html

def generate_infographic_complete(deep, book_title):
    deep_text = _coerce_deep_text(deep, book_title)
    print(f"ğŸ§ª deep_text chars = {len(deep_text)}")
    user_text = _build_user_text(deep_text, book_title)
    html, usage = _call_claude(user_text)

    start = re.search(r'(?is)(<!DOCTYPE\s+html[^>]*>|<html\b[^>]*>)', html)
    if start:
        html = html[start.start():]
    end = re.search(r'(?is)</html\s*>', html)
    if end:
        html = html[:end.end()]

    if (not html) or (len(html.strip()) < 200) or ('<html' not in html.lower()):
        print("âš ï¸ ç”ŸæˆHTMLãŒä¸ååˆ†ãªãŸã‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆã—ã¾ã™ã€‚")
        tpl = _read_template()
        if tpl:
            fields = _extract_fields_for_template(deep_text)
            tpl = tpl.replace("ã€æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã“ã“ã«è¨˜è¼‰ã€‘", fields.get("æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸","ä¸æ˜"))
            tpl = tpl.replace("ã€ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã‚’ã“ã“ã«è¨˜è¼‰ã€‘", fields.get("ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼","ä¸æ˜"))
            try:
                if fields.get("æ¦‚å¿µ_list"):
                    first = fields["æ¦‚å¿µ_list"][0]
                    term = first.get("æ¦‚å¿µ") or first.get("term") or ""
                    definition = first.get("è§£èª¬") or first.get("definition") or ""
                    tpl = tpl.replace("ã€æ¦‚å¿µåã€‘", term or "ä¸æ˜")
                    tpl = tpl.replace("ã€æ¦‚å¿µã®å®šç¾©ãƒ»èª¬æ˜ã€‘", definition or "ä¸æ˜")
            except Exception:
                pass
            html = tpl
        else:
            html = "<!DOCTYPE html><html><head><meta charset='utf-8'><title>{}</title></head><body><pre>{}</pre></body></html>".format(
                book_title or "infographic", (deep_text[:10000] + "...") if len(deep_text)>10000 else deep_text
            )

    name = f"{_slug(book_title)}_infographic.html"
    name = f"{_slug(book_title)}_infographic.html"
    out_path = Path(INF_DIR) / name  # â˜… HTML ã¯ infographics ã«ä¿å­˜
    _atomic_write(str(out_path), html)
    print(f"ğŸ—‚ å‡ºåŠ›ä¿å­˜: {out_path}")

    # äº’æ›: çµ¶å¯¾ file:// URL
    file_url = "file://" + quote(str(out_path.resolve()))
    # Vaultç›¸å¯¾ãƒªãƒ³ã‚¯
    vault_rel = _vault_relative(out_path)
    # 2ç¨®ã®URIï¼ˆæ—§ãƒ•ãƒ­ãƒ¼äº’æ›: è¿”å´ç”¨ã«ä¿æŒã™ã‚‹ãŒãƒãƒ¼ãƒˆã«ã¯ä½¿ã‚ãªã„ï¼‰
    ob_uri  = _obsidian_uri_for(vault_rel)
    app_uri = _app_local_uri(vault_rel)

    # === GitHub Pages ã¸å…¬é–‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰ ===
    public_url, _warn = _publish_to_github_pages(
        local_html_path=str(out_path),
        filename=name,
        vault_rel=vault_rel,
        file_url=file_url,
        title_for_note=(book_title or name)
    )
    infographic_url = public_url  # ä»¥é™ã®è¿”å´/ãƒ†ãƒ³ãƒ—ãƒ¬å¤‰æ•°ã¯ã“ã®URL

    # === Usage æŠ½å‡ºï¼ˆinput/output tokensï¼‰===
    usage_dict = {}
    if usage:
        def _get(d,k,default=0):
            try:
                return int(getattr(d,k)) if hasattr(d,k) else int(d.get(k, default))
            except Exception:
                return default
        usage_dict = {
            "model": MODEL,
            "input_tokens": _get(usage,"input_tokens"),
            "output_tokens": _get(usage,"output_tokens"),
        }
    in_tok  = int((usage_dict or {}).get("input_tokens", 0) or 0)
    out_tok = int((usage_dict or {}).get("output_tokens", 0) or 0)

    # === ã‚³ã‚¹ãƒˆã¨ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆï¼ˆ$/ç™¾ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³åŸºæº–ï¼‰ ===
    rate_in_le  = float(os.getenv("ANTHROPIC_PRICE_INPUT_LE200K",  "3"))
    rate_in_gt  = float(os.getenv("ANTHROPIC_PRICE_INPUT_GT200K",  "6"))
    rate_out_le = float(os.getenv("ANTHROPIC_PRICE_OUTPUT_LE200K", "15"))
    rate_out_gt = float(os.getenv("ANTHROPIC_PRICE_OUTPUT_GT200K", "22.50"))

    rate_in  = rate_in_gt  if in_tok  > 200_000 else rate_in_le
    rate_out = rate_out_gt if out_tok > 200_000 else rate_out_le

    cost_usd = (in_tok/1_000_000.0)*rate_in + (out_tok/1_000_000.0)*rate_out

    try:
        credit_start = float(((os.getenv("CLAUDE_START_CREDIT") or "19.19")).replace(",", ""))
    except Exception:
        credit_start = 19.19
    credit_remain = max(credit_start - cost_usd, 0.0)

    # â˜… Obsidian ãƒãƒ¼ãƒˆã®å¤‰æ•°
    obs_vars = {
        "{{infographic_url}}": infographic_url,
        "{{claude_usaget}}":  out_tok,
        "{{claude_credit}}": f"${credit_remain:.2f}",
    }

    # === JSON ä¿å­˜ï¼ˆvariables / cost_usd / public_url ã‚’å«ã‚ã¦ä¿å­˜ï¼‰ ===
    agg_path = Path(DATA_DIR) / "infographics.json"
    try:
        if agg_path.exists():
            arr = json.loads(agg_path.read_text(encoding="utf-8"))
            if not isinstance(arr, list):
                arr = []
        else:
            arr = []
        meta = {
            "title": book_title or "",
            "file_url": file_url,
            "vault_rel": vault_rel,
            "obsidian_uri": ob_uri,
            "app_local_uri": app_uri,
            "html_path": str(out_path),
            "model": MODEL,
            "usage": usage_dict,
            "generated_at": datetime.datetime.now().isoformat(timespec="seconds"),
            "public_url": infographic_url,
            "variables": obs_vars,
            "cost_usd": cost_usd,
        }
        arr.append(meta)
        _atomic_write(str(agg_path), json.dumps(arr, ensure_ascii=False, indent=2))
        print(f"ğŸ—‚ JSONä¿å­˜: {agg_path}")
    except Exception as e:
        print(f"âš ï¸ JSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    return {
        "path": str(agg_path),
        "html_path": str(out_path),
        "json": meta,
        "usage": usage_dict,
        "file_url": file_url,
        "vault_rel": vault_rel,
        "obsidian_uri": ob_uri,
        "app_local_uri": app_uri,
        "{{infographic_url}}": infographic_url,
        "{{claude_usaget}}":  out_tok,
        "{{claude_credit}}": f"${credit_remain:.2f}",
    }

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 3:
        print("Usage: python claude_infographic.py <deep_text_file> <book_title>")
        sys.exit(1)

    deep_file = Path(sys.argv[1])
    book_title = sys.argv[2]
    deep_arg = ""
    if deep_file.exists():
        txt = deep_file.read_text(encoding="utf-8")
        print(f"ğŸ” deep/raw èª­ã¿è¾¼ã¿: {deep_file} ({len(txt)} chars)")
        deep_arg = txt
    else:
        print(f"âš  deep file not found: {deep_file}")

    res = generate_infographic_complete(deep_arg, book_title)
    print("âœ… ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç”Ÿæˆå®Œäº†")
