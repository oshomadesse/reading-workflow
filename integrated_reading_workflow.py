#!/usr/bin/env python3
"""
çµ±åˆèª­æ›¸ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆå®Ÿé‹ç”¨ãƒ¢ãƒ¼ãƒ‰ãƒ»usageè‡ªå‹•å–å¾—ãƒ»é€²æ—ãƒ­ã‚°å¼·åŒ–ï¼‰
--until 7 ã¾ã§ï¼šStep6ã§ä¸­é–“ã‚µãƒãƒªç¢ºèª â†’ Step7ã§ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import argparse
import sys
import os
import traceback
from dotenv import load_dotenv
import importlib.util
import json
import pathlib
import re
from pathlib import Path
from datetime import datetime

# æ—¢å­˜ä»•æ§˜ã‚’å°Šé‡ï¼šStep1-3ã¯å¤‰æ›´ã—ãªã„ï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ãã®ã¾ã¾ä¿æŒï¼‰
import chatgpt_research as gemini_research
from gemini_recommend import GeminiConnector as GeminiRecommendConnector
try:
    from gemini_recommend import FLASH_MODEL
except Exception:
    FLASH_MODEL = getattr(gemini_research, "FLASH_MODEL", "gemini-2.5-flash")

import claude_infographic

# ============ ç’°å¢ƒèª­ã¿è¾¼ã¿ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¿è¨¼ ============
# ============ ç’°å¢ƒèª­ã¿è¾¼ã¿ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¿è¨¼ ============
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))
# CIç’°å¢ƒï¼ˆGITHUB_ACTIONSï¼‰ã®å ´åˆã¯ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã‚’VAULT_ROOTã¨ã¿ãªã™
if os.getenv("GITHUB_ACTIONS"):
    VAULT_ROOT = Path(PROJECT_DIR).resolve()
    INBOX_DIR = VAULT_ROOT / "artifacts" # ãƒªãƒã‚¸ãƒˆãƒªå†…ã«ä½œæˆï¼ˆæ—§ 100_Inboxï¼‰
else:
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®æ¨æ¸¬
    VAULT_ROOT = Path(os.getenv("VAULT_ROOT", "/Users/seihoushouba/Documents/Oshomadesse-pc")).resolve()
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›: ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ã¯ oshomadesse-pc > 100_Inbox (ã¤ã¾ã‚Š VAULT_ROOT ç›´ä¸‹ã® 100_Inbox)
    INBOX_DIR = Path(os.getenv("INBOX_DIR", str(VAULT_ROOT / "100_Inbox"))).resolve()

try:
    load_dotenv(os.path.join(PROJECT_DIR, ".env"))
except Exception:
    load_dotenv()

def _ensure_dirs():
    for d in (
        os.path.join(PROJECT_DIR, "infographics"),
        os.path.join(PROJECT_DIR, "data"),
        str(INBOX_DIR),
    ):
        os.makedirs(d, exist_ok=True)
_ensure_dirs()

LOG_DIR = os.path.join(PROJECT_DIR, "data", "integrated")
os.makedirs(LOG_DIR, exist_ok=True)
_DEFAULT_RUN_LOG = os.path.join(LOG_DIR, "integrated_run_" + datetime.now().strftime("%Y%m%d") + ".log")
def _make_printer(logfile):
    import builtins as _bi
    def _p(*a, **k):
        _bi.print(*a, **k)
        try:
            with open(logfile, "a", encoding="utf-8") as fp:
                _bi.print(*a, **k, file=fp)
        except Exception:
            pass
    return _p
RUN_LOG = os.environ.get("IRW_LOGFILE", _DEFAULT_RUN_LOG)
print = _make_printer(RUN_LOG)
print("Logging to: " + str(RUN_LOG))

CLAUDE_CREDIT_START = float(os.getenv("CLAUDE_START_CREDIT", "18.35"))
CHATGPT_CREDIT_START = float(os.getenv("CHATGPT_START_CREDIT", "4.92"))

def _should_use_responses(model: str) -> bool:
    """
    gpt-5 ç³»ã¯ Responses API ã‚’å„ªå…ˆã€‚ç’°å¢ƒå¤‰æ•° OPENAI_USE_RESPONSES=1 ã§ã‚‚å¼·åˆ¶ã€‚
    """
    if os.getenv("OPENAI_USE_RESPONSES","").strip().lower() in ("1","true"):
        return True
    m = (model or "").lower()
    return m.startswith("gpt-5")

def step0_diag_env(probe=False, model_hint=None):
    print("ğŸ”§ ç’°å¢ƒè¨ºæ–­é–‹å§‹")
    keys = {
        "OPENAI_API_KEY": (os.getenv("OPENAI_API_KEY")[:6] + "...") if os.getenv("OPENAI_API_KEY") else "(unset)",
        "ANTHROPIC_API_KEY": (os.getenv("ANTHROPIC_API_KEY")[:6] + "...") if os.getenv("ANTHROPIC_API_KEY") else "(unset)",
        "GEMINI_API_KEY": (os.getenv("GEMINI_API_KEY")[:6] + "...") if os.getenv("GEMINI_API_KEY") else "(unset)",
        "CHATGPT_START_CREDIT": os.getenv("CHATGPT_START_CREDIT") or os.getenv("chatgpt_start_credit") or "(unset)",
        "CLAUDE_START_CREDIT": os.getenv("CLAUDE_START_CREDIT") or "(unset)"
    }
    try:
        print(json.dumps(keys, ensure_ascii=False, indent=2))
    except Exception:
        print(keys)

    for d in (
        str(PROJECT_DIR),
        os.path.join(PROJECT_DIR, "data"),
        os.path.join(PROJECT_DIR, "infographics"),
        str(INBOX_DIR),
    ):
        try:
            os.makedirs(d, exist_ok=True)
            print(f"DIR OK: {d}")
        except Exception as e:
            print(f"DIR NG: {d} -> {e}")

    if not probe:
        print("â„¹ï¸ probeæœªå®Ÿè¡Œï¼ˆ--probeæŒ‡å®šã§æœ€å°LLMãƒªã‚¯ã‚¨ã‚¹ãƒˆæ¤œè¨¼ï¼‰")
        return

    # --- ã“ã“ã‹ã‚‰: ãƒ—ãƒ­ãƒ¼ãƒ–ï¼ˆResponses/ChatCompletions ã‚’ãƒ¢ãƒ‡ãƒ«ã§è‡ªå‹•åˆ‡æ›¿ï¼‰ ---
    try:
        from openai import OpenAI
        client = OpenAI()
        model = model_hint or os.getenv("GPT5_MODEL", "gpt-5")
        print(f"OpenAI probe model={model}")

        if _should_use_responses(model):
            r = client.responses.create(
                model=model,
                input=[{"role":"user","content":"Return exactly the word: pong"}],
                max_output_tokens=32
            )
            txt = (getattr(r, "output_text", None) or "").strip()
            u = getattr(r, "usage", None)
            usage = {}
            if u:
                def _g(obj, name, alt=None):
                    return getattr(obj, name, None) if hasattr(obj, name) else (obj.get(name) if isinstance(obj, dict) else alt)
                inp = int(_g(u,"input_tokens",0) or 0)
                out = int(_g(u,"output_tokens",0) or 0)
                tot = int(_g(u,"total_tokens",inp+out) or (inp+out))
                usage = {"input_tokens": inp, "output_tokens": out, "total_tokens": tot}
        else:
            r = client.chat.completions.create(
                model=model,
                messages=[{"role":"user","content":"Return exactly the word: pong"}],
                max_tokens=32
            )
            txt = r.choices[0].message.content if getattr(r, "choices", None) else ""
            u = getattr(r, "usage", None)
            usage = {}
            if u:
                inp = int(getattr(u,"prompt_tokens",0) or 0)
                out = int(getattr(u,"completion_tokens",0) or 0)
                tot = int(getattr(u,"total_tokens", inp+out) or (inp+out))
                usage = {"input_tokens": inp, "output_tokens": out, "total_tokens": tot}

        print(f"LLMå¿œç­”: {txt!r}")
        print(f"usage: {usage}")
    except Exception as e:
        print("âŒ OpenAIãƒ—ãƒ­ãƒ¼ãƒ–å¤±æ•—:", e)

# Sheets ã¯å­˜åœ¨ã—ãªã„å¯èƒ½æ€§ã‚ã‚Šï¼ˆå®Ÿé‹ç”¨æ™‚ã¯ç½®ãï¼‰
try:
    import sheets_connector
except Exception:
    sheets_connector = None

# ============ Step1: é™¤å¤–æœ¬å–å¾— ============
def step1_get_excluded_books():
    print("ğŸ“Š é™¤å¤–æœ¬ãƒªã‚¹ãƒˆå–å¾—ä¸­ï¼ˆGoogle Sheetsï¼‰...")
    if sheets_connector and hasattr(sheets_connector, "get_excluded_books"):
        try:
            excluded_books = sheets_connector.get_excluded_books()
            print(f"âœ… é™¤å¤–æœ¬ãƒªã‚¹ãƒˆå–å¾—æˆåŠŸ: {len(excluded_books)}å†Š")
            return excluded_books or []
        except Exception as e:
            print(f"âš  Sheetså–å¾—ã«å¤±æ•—: {e} â†’ ç©ºãƒªã‚¹ãƒˆã§ç¶™ç¶š")
            return []
    else:
        print("âš  sheets_connector æœªè¨­å®š â†’ ç©ºãƒªã‚¹ãƒˆã§ç¶™ç¶š")
        return []

# ============ Step2: Geminiã§æœ¬æ¨è–¦ ============
def step2_generate_recommendations(excluded, usage_records):
    """
    å¼·åŒ–ç‰ˆ Step2:
    - excluded ã‚’å¼·åˆ¶çš„ã«ã‚¿ã‚¤ãƒˆãƒ«æ–‡å­—åˆ—ãƒªã‚¹ãƒˆã¸å¤‰æ›
    - API ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ã—ã¦æ•´å½¢
    - ãƒ­ãƒ¼ã‚«ãƒ«ã§äºŒé‡é™¤å¤–ï¼ˆis_banned_titleï¼‰ã‚’è¡Œã„ã€ãƒ¢ãƒ‡ãƒ«ãŒé™¤å¤–ã‚’ç„¡è¦–ã—ã¦ã‚‚å¼¾ã
    """
    def _coerce_to_title_list(excluded_input):
        titles = []
        if not excluded_input:
            return titles
        if isinstance(excluded_input, dict):
            t = excluded_input.get("title") or excluded_input.get("name") or ""
            if t:
                titles.append(str(t).strip())
            return titles
        if isinstance(excluded_input, (list, tuple, set)):
            for e in excluded_input:
                if isinstance(e, dict):
                    t = e.get("title") or e.get("name") or ""
                else:
                    t = str(e)
                t = (t or "").strip()
                if t:
                    titles.append(t)
            return titles
        return [str(excluded_input).strip()]

    def _validate(raw, target=5):
        out = []
        if not isinstance(raw, list):
            return out
        for item in raw:
            if not isinstance(item, dict):
                continue
            title = (item.get("title") or "").strip()
            if not title:
                continue
            out.append({
                "title": title,
                "author": (item.get("author") or "").strip(),
                "category": (item.get("category") or "").strip(),
                "reason": (item.get("reason") or "").strip()
            })
            if len(out) >= target:
                break
        return out

    # 1) å…¥åŠ›ã®æ­£è¦åŒ–ï¼ˆå¸¸ã«æ–‡å­—åˆ—ã‚¿ã‚¤ãƒˆãƒ«ãƒªã‚¹ãƒˆã«ï¼‰
    excluded_titles = _coerce_to_title_list(excluded)
    print("DEBUG: excluded_titles ->", excluded_titles)

    # 2) ã‚³ãƒã‚¯ã‚¿æº–å‚™
    connector = GeminiRecommendConnector(verbose=True)
    print("âœ… Gemini Connector æº–å‚™å®Œäº†")
    print(f"   ğŸ“š æœ¬æ¨è–¦: {FLASH_MODEL}")

    # 3) æ¨è–¦å–å¾—
    print("ğŸ” Gemini ã§æœ¬æ¨è–¦ä¸­...")
    raw_result = connector.get_book_recommendations(excluded_titles)

    # 4) æ¤œè¨¼ãƒ»æ•´å½¢
    validated = _validate(raw_result, target=5)

    # 5) ãƒ­ãƒ¼ã‚«ãƒ«ã§äºŒé‡é™¤å¤–ï¼ˆis_banned_title ã‚’åˆ©ç”¨ï¼‰
    final = []
    for item in validated:
        title = item["title"]
        try:
            if is_banned_title(title, excluded_titles, final):
                if getattr(connector, "verbose", False):
                    print(f"DEBUG: filtered out (in excluded list or similar): {title}")
                continue
        except Exception:
            # é™¤å¤–åˆ¤å®šã§å•é¡ŒãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶™ç¶šã™ã‚‹
            pass
        final.append(item)
        if len(final) >= 5:
            break

    # 6) è¡¨ç¤ºãƒ»usageè¨˜éŒ²
    titles = [i["title"] for i in final]
    print("ğŸ“ æ¨è–¦ï¼ˆé™¤å¤–é©ç”¨å¾Œï¼‰: " + ", ".join(titles))

    usage_records["gemini_step2"] = {
        "model": FLASH_MODEL,
        "input_tokens": 500,
        "output_tokens": 700,
        "rpm": 2, "tpm": 200000, "rpd": 50
    }
    return final

# é¡ä¼¼ï¼åŒä¸€åˆ¤å®šï¼ˆStep2å†…éƒ¨ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ãƒ˜ãƒ«ãƒ‘ã€‚æ—¢å­˜å‹•ä½œã‚’é‚ªé­”ã—ãªã„ç´ ç›´åˆ¤å®šï¼‰
def is_banned_title(candidate, excluded_titles, current_list):
    try:
        import re, unicodedata
        def norm(s):
            s = unicodedata.normalize("NFKC", str(s)).lower()
            s = re.sub(r"[\s\-_ãƒ»ã€ã€‚.,/|]+", "", s)
            return s
        cn = norm(candidate)
        pool = [norm(t) for t in (excluded_titles or [])]
        pool += [norm(d.get("title")) for d in (current_list or []) if isinstance(d, dict) and d.get("title")]
        return cn in set(pool)
    except Exception:
        return False

# ============ Step3: æ¨è–¦ã‹ã‚‰æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸å‡º ============
def step3_select_book(recommendations):
    import random, os
    print("=========== Step3: æ¨è–¦ã‹ã‚‰æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸å‡º ===========")
    if not recommendations:
        raise ValueError("æ¨è–¦ãŒç©ºã§ã™ã€‚Step2ã®å‡ºåŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    seed_env = os.getenv("RANDOM_SEED")
    if seed_env and seed_env.isdigit():
        random.seed(int(seed_env))
        print(f"ğŸ² ãƒ©ãƒ³ãƒ€ãƒ é¸å‡ºï¼ˆå†ç¾ã‚·ãƒ¼ãƒ‰: {seed_env}ï¼‰")
    else:
        print("ğŸ² ãƒ©ãƒ³ãƒ€ãƒ é¸å‡ºï¼ˆéæ±ºå®šï¼‰")
    for i, it in enumerate(recommendations, 1):
        title = (it.get("title") if isinstance(it, dict) else str(it))
        print(f"   å€™è£œ{i}: {title}")
    idx = random.randrange(len(recommendations))
    sel = recommendations[idx]
    title = (sel.get("title") if isinstance(sel, dict) else str(sel))
    print(f"âœ… é¸æŠæœ¬: {idx+1}/{len(recommendations)} â†’ {title}")
    return sel

# ============ Step4: Deep Research ============
def step4_deep_research(book, usage_records):
    print("   Deep Research: GPT-5")
    import json, traceback, chatgpt_research
    title = book.get("title") if isinstance(book, dict) else str(book)
    author = book.get("author") if isinstance(book, dict) else ""
    category = book.get("category") if isinstance(book, dict) else ""
    res = None
    try:
        ConnectorClass = (
            getattr(chatgpt_research, "ChatGPTConnector", None)
            or getattr(chatgpt_research, "GeminiConnector", None)
            or getattr(chatgpt_research, "GeminiResearchConnector", None)
        )
        connector = ConnectorClass(verbose=True) if ConnectorClass else None
        if connector and hasattr(connector, "get_deep_research_json"):
            try:
                res = connector.get_deep_research_json(title, author, category=category)
            except Exception:
                res = None
        if not res and connector and hasattr(connector, "deep_research"):
            try:
                res = connector.deep_research(title, author)
            except Exception:
                res = None
    except Exception:
        traceback.print_exc()
        res = None
    out = {}
    try:
        if isinstance(res, dict):
            out = res
        elif isinstance(res, str):
            s2 = res.strip()
            if s2:
                try:
                    out = json.loads(s2)
                except Exception:
                    out = {"overview": s2}
            else:
                out = {}
        elif res is None:
            out = {}
        else:
            try:
                out = json.loads(str(res))
            except Exception:
                out = {"overview": str(res)}
    except Exception as e:
        print("ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ­£è¦åŒ–ã§ä¾‹å¤–: " + str(e))
        traceback.print_exc()
        out = {}
    u = {}
    try:
        u = out.get("usage") or {}
    except Exception:
        u = {}
    def _to_int(x, d=0):
        try:
            return int(x or d)
        except Exception:
            try:
                return int(float(x))
            except Exception:
                return d
    in_tok = _to_int(u.get("input_tokens"), 0)
    out_tok = _to_int(u.get("output_tokens"), 0)
    total_tok = _to_int(out.get("chatgpt_usaget", u.get("total_tokens") if isinstance(u, dict) else 0), in_tok + out_tok)
    if total_tok and (in_tok + out_tok) == 0:
        in_tok = int(total_tok * 6 // 10)
        out_tok = total_tok - in_tok
    usage_records["chatgpt_step4"] = {
        "model": str(getattr(chatgpt_research, "PRO_MODEL", "gpt-5")),
        "input_tokens": in_tok,
        "output_tokens": out_tok,
        "total_tokens": total_tok,
        "note": "via GPT-5 deep research"
    }
    # è¿”å´ã« raw é•·ãŒç„¡ã„å ´åˆã«å‚™ãˆã€ã“ã“ã§æ¦‚ç®—é•·ã‚’ä»˜ä¸
    try:
        deep_len = len(str(out.get("raw") or "")) if isinstance(out, dict) else len(str(out))
    except Exception:
        deep_len = len(json.dumps(out, ensure_ascii=False))
    out["_raw_len"] = deep_len
    print(f"â„¹ï¸ Deep Research length: {deep_len} chars")
    return out

# ============ Step5: Claudeã§ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç”Ÿæˆï¼ˆå…¬é–‹URL/ä½¿ç”¨é‡/æ®‹é«˜ å–ã‚Šè¾¼ã¿ï¼‰ ============
def step5_generate_infographic(deep_research_text, book, usage_records):
    print("ğŸ›  Claudeã§ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç”Ÿæˆä¸­ï¼ˆdeepã‚’æ¸¡ã™ï¼‰...")
    res = None
    try:
        title = (book.get("title") if isinstance(book, dict) else str(book)) or ""
        if hasattr(claude_infographic, "generate_infographic_complete"):
            try:
                res = claude_infographic.generate_infographic_complete(deep_research_text or {}, title)
            except TypeError:
                res = claude_infographic.generate_infographic(deep_research_text, title)
        else:
            res = claude_infographic.generate_infographic(deep_research_text, title)
    except Exception as e:
        print("âš  ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç”Ÿæˆã§ä¾‹å¤–:", e)
        res = None
    print("âœ… ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ç”Ÿæˆå®Œäº†")

    # usageæŠ½å‡ºï¼ˆå®Ÿå€¤ã§ä¸Šæ›¸ãï¼‰
    in_tok, out_tok = 0, 0
    model = "claude-4-sonnet"
    if isinstance(res, dict):
        u = res.get("usage") or {}
        model = (u.get("model") or res.get("json", {}).get("model") or model)
        try:
            in_tok = int(u.get("input_tokens", u.get("prompt_tokens", in_tok)) or in_tok)
        except Exception:
            pass
        try:
            out_tok = int(u.get("output_tokens", u.get("completion_tokens", out_tok)) or out_tok)
        except Exception:
            pass
    usage_records["infographic"] = {
        "model": model,
        "input_tokens": in_tok,
        "output_tokens": out_tok
    }

    # è¿½åŠ : å…¬é–‹URL / æ®‹é«˜
    infographic_url = ""
    claude_usaget = 0
    claude_credit = ""
    if isinstance(res, dict):
        infographic_url = (
            res.get("infographic_url")
            or res.get("{{infographic_url}}")
            or (res.get("json") or {}).get("public_url")
            or ""
        )
        claude_usaget = res.get("claude_usaget") or res.get("{{claude_usaget}}") or claude_usaget
        claude_credit = res.get("claude_credit") or res.get("{{claude_credit}}") or ""

        # å‘¼ã³å‡ºã—å´ï¼ˆStep6ï¼‰ãŒä½¿ã„ã‚„ã™ã„ã‚ˆã†ã«ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«æ­£è¦åŒ–ã‚­ãƒ¼ã‚’ä»˜ä¸
        res["infographic_url"] = infographic_url
        res["claude_usaget"] = claude_usaget
        res["claude_credit"] = claude_credit

    if isinstance(res, dict):
        return res
    if isinstance(res, str):
        return {
            "path": "",
            "html_path": "",
            "json": {},
            "usage": {"model": model, "input_tokens": in_tok, "output_tokens": out_tok},
            "infographic_url": infographic_url,
            "claude_usaget": claude_usaget,
            "claude_credit": claude_credit,
        }
    return {
        "path": "",
        "html_path": "",
        "json": {},
        "usage": {"model": model, "input_tokens": in_tok, "output_tokens": out_tok},
        "infographic_url": infographic_url,
        "claude_usaget": claude_usaget,
        "claude_credit": claude_credit,
    }


# ============ Step6: ä¸­é–“ã‚µãƒãƒªï¼ˆãƒãƒ¼ãƒˆæ§‹æˆã«å¿…è¦ãªå¤‰æ•°ã®å€¤ä¸€è¦§ï¼‰ ============
def step6_mid_summary(book, deep_research, infographic_result):
    def _get(d, k, default=""):
        try:
            v = d.get(k)
            return v if v is not None else default
        except Exception:
            return default

    def _as_text(x):
        if isinstance(x, str):
            return x.strip()
        if isinstance(x, (list, tuple)):
            return " / ".join([_as_text(v) for v in x if v is not None and str(v).strip()])
        if isinstance(x, dict):
            for k in ("text","value","content","æ¦‚è¦","è¦ç´„","summary","message"):
                v = x.get(k)
                if isinstance(v, str) and v.strip():
                    return v.strip()
            try:
                return json.dumps(x, ensure_ascii=False)
            except Exception:
                return str(x)
        return "" if x is None else str(x).strip()

    # === è¿½åŠ : ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æŠ½å‡ºç³»ï¼ˆdeep_researchãŒä¸å®Œå…¨ã§ã‚‚è‡ªå·±ä¿®å¾©ï¼‰ ===
    def _nfkc_lower(s: str) -> str:
        import unicodedata, re as _re
        s = unicodedata.normalize("NFKC", str(s)).lower()
        s = _re.sub(r"\s+", "", s)
        s = _re.sub(r"[0-9_]+", "", s)
        s = _re.sub(r"[ -/:-@\[-`{-~]", "", s)  # ASCIIè¨˜å·ã®ã¿é™¤å»ï¼ˆCJKã¯ä¿æŒï¼‰
        return s

    def _dig_any(d, keys):
        if not isinstance(d, dict): return None
        targets = [_nfkc_lower(k) for k in keys if k]
        for k, v in d.items():
            nk = _nfkc_lower(k)
            for t in targets:
                if t and t in nk:
                    return v
            if isinstance(v, dict):
                r = _dig_any(v, keys)
                if r is not None: return r
            if isinstance(v, list):
                for it in v:
                    if isinstance(it, dict):
                        r = _dig_any(it, keys)
                        if r is not None: return r
        return None

    def _strip_code_fences(t: str) -> str:
        import re as _re
        if not isinstance(t, str): return ""
        return _re.sub(r"```.*?```", "", t, flags=_re.S)

    def _grab_block(label_patterns, text: str) -> str:
        import re as _re
        head = r"(?:\d+[\.\)]\s*)?"
        labels = "|".join([_re.escape(lp) for lp in label_patterns])
        pat = rf"(?ms)^\s*{head}(?:{labels})(?:ï¼ˆ.*?ï¼‰)?\s*[:ï¼š]?\s*\n?(?P<body>.+?)(?=^\s*{head}(æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸|æ ¸å¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸|ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼|ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼|Executive Summary|Core Message|é–¢é€£æ›¸ç±|Related Books)\b|\Z)"
        m = _re.search(pat, text or "")
        return _re.sub(r"^[\-\*\â€¢ãƒ»]\s*", "", m.group('body'), flags=_re.M).strip() if m else ""

    def _first_nonempty(*vals) -> str:
        for v in vals:
            s = _as_text(v)
            if s: return s
        return ""

    # è¿½åŠ : JSONæ–‡å­—åˆ—ã‚’å®‰å…¨ã«dictã¸
    def _json_from_text(text: str):
        if not isinstance(text, str) or not text.strip(): return None
        import re as _re
        s = _strip_code_fences(text).strip()
        s = s.replace("â€œ", '"').replace("â€", '"').replace("â€™", "'").replace("â€˜", "'")
        s = _re.sub(r",\s*([\]\}])", r"\1", s)
        # 1) å…¨ä½“ãŒJSON
        if (s.startswith("{") and s.endswith("}")) or (s.startswith("[") and s.endswith("]")):
            try:
                j = json.loads(s)
                if isinstance(j, dict): return j
                if isinstance(j, list) and j and isinstance(j[0], dict): return j[0]
            except Exception:
                pass
        # 2) æœ€åˆã«è¦‹ã¤ã‹ã‚‹JSONãƒ–ãƒ­ãƒƒã‚¯
        m = _re.search(r"(\{[\s\S]*\}|\[[\s\S]*\])", s)
        if m:
            try:
                j = json.loads(m.group(1))
                if isinstance(j, dict): return j
                if isinstance(j, list) and j and isinstance(j[0], dict): return j[0]
            except Exception:
                return None
        return None

    # JSONã£ã½ã„æ–‡å­—åˆ—ã«å¯¾ã—ã¦ã€ãã®å ´ã§å†æŠ½å‡º
    def _maybe_json_fix(s: str, keys):
        if not isinstance(s, str): return s
        ss = s.strip()
        if ss.startswith("{") or ss.startswith("["):
            j = _json_from_text(ss)
            if isinstance(j, dict):
                v = _dig_any(j, list(keys))
                return _as_text(v) or s
        return s

    # related_books ãŒé…åˆ—/è¾æ›¸ã®å ´åˆã®æ•´å½¢
    def _format_related(x):
        if isinstance(x, str): return x.strip()
        buf=[]
        if isinstance(x, list):
            for it in x:
                if isinstance(it, str) and it.strip():
                    buf.append(it.strip())
                elif isinstance(it, dict):
                    t = it.get("æ›¸å") or it.get("title") or it.get("name") or ""
                    a = it.get("è‘—è€…") or it.get("author") or it.get("authors") or ""
                    r = it.get("é–¢é€£æ€§") or it.get("reason") or it.get("èª¬æ˜") or ""
                    t = str(t).strip(); a = str(a).strip(); r = str(r).strip()
                    base = f"{t}ï¼ˆ{a}ï¼‰" if (t and a) else (t or a)
                    s = f"{base}: {r}" if r and base else (base or r)
                    if s: buf.append(s)
                else:
                    s = _as_text(it)
                    if s: buf.append(s)
        elif isinstance(x, dict):
            return _as_text(x)
        return " / ".join(buf).strip()

    # ==== book åŸºæœ¬ ====
    title = (book.get("title") if isinstance(book, dict) else str(book)) or ""
    author = (book.get("author") if isinstance(book, dict) else "") or ""
    category = (book.get("category") if isinstance(book, dict) else "") or ""

    # ==== deep_research æ­£è¦åŒ– ====
    dr = deep_research if isinstance(deep_research, dict) else {}
    raw_text = _as_text(dr.get("raw")) if isinstance(dr, dict) else ""
    parsed = dr.get("parsed") if isinstance(dr, dict) else None

    # é‡è¦: ç©ºdictã‚‚ç„¡åŠ¹æ‰±ã„ã«ã—ã¦ raw ã‹ã‚‰å†ãƒ‘ãƒ¼ã‚¹
    if (not isinstance(parsed, dict)) or (isinstance(parsed, dict) and not parsed):
        # chatgpt_research å´ã§ JSONã‚’è¿”ã—æã­ãŸå ´åˆã®æ•‘æ¸ˆ
        j = _json_from_text(raw_text)
        parsed = j if isinstance(j, dict) else {}

    # ==== ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆç¢ºå®Ÿã«åŸ‹ã‚ã‚‹ï¼‰ ====
    research_url = _first_nonempty(dr.get("research_url"), "")

    core_message = _first_nonempty(
        dr.get("core_message"),
        _dig_any(parsed, ["æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸","æ ¸å¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸","core_message","coremessage","core_messeage"]),
        _grab_block(["æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸","æ ¸å¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸","Core Message"], _strip_code_fences(raw_text)),
        _strip_code_fences(raw_text)[:350] if raw_text else ""
    )
    # JSONã£ã½ã‘ã‚Œã°ã“ã“ã§å†æŠ½å‡º
    core_message = _maybe_json_fix(core_message, ["æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸","æ ¸å¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸","core_message","coremessage"])

    executive_summary = _first_nonempty(
        dr.get("executive_summary"),
        _dig_any(parsed, ["ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼","ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼","executive_summary","execsummary","executivesummary"]),
        _grab_block(["ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼","ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼","Executive Summary","è¦ç´„","æ¦‚è¦","ã¾ã¨ã‚"], _strip_code_fences(raw_text)),
        _strip_code_fences(raw_text)[:600] if raw_text else ""
    )
    executive_summary = _maybe_json_fix(executive_summary, ["ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼","ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼","executive_summary","execsummary","executivesummary"])

    related_books = _first_nonempty(
        dr.get("related_books"),
        _dig_any(parsed, ["é–¢é€£æ›¸ç±","related_books","relatedbooks","å‚è€ƒæ–‡çŒ®","é–¢é€£æ–‡çŒ®"]),
        _grab_block(["é–¢é€£æ›¸ç±","Related Books","å‚è€ƒæ–‡çŒ®","é–¢é€£æ–‡çŒ®"], _strip_code_fences(raw_text))
    )
    # é…åˆ—ãƒ»è¾æ›¸ã«ã‚‚å¯¾å¿œ
    if not isinstance(related_books, str):
        related_books = _format_related(related_books)
    else:
        related_books = _maybe_json_fix(related_books, ["é–¢é€£æ›¸ç±","related_books","relatedbooks","å‚è€ƒæ–‡çŒ®","é–¢é€£æ–‡çŒ®"])

    practical_actions = _first_nonempty(
        dr.get("practical_actions"),
        _dig_any(parsed, ["ä»Šæ—¥ã§ãã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³","ä»Šæ—¥ã§ãã‚‹è¡Œå‹•","ä»Šæ—¥è¡Œãˆã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³","todayactions","today_action","immediateactions","å®Ÿè·µ","ã‚¢ã‚¯ã‚·ãƒ§ãƒ³","å…·ä½“è¡Œå‹•","actions","recommendations"])
    )

    # ==== ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3ä»¶æŠ½å‡º ====
    if isinstance(practical_actions, str):
        actions = [a.strip() for a in practical_actions.split(" / ") if a.strip()]
    elif isinstance(practical_actions, (list, tuple)):
        actions = [str(a).strip() for a in practical_actions if str(a).strip()]
    else:
        actions = []
    actions = (actions + ["", "", ""])[:3]
    action_a, action_b, action_c = actions

    # ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯
    inf_path = ""
    if isinstance(infographic_result, dict):
        inf_path = infographic_result.get("html_path") or infographic_result.get("path") or ""
    infographic_url = ""
    claude_usaget = 0
    claude_credit = ""
    if isinstance(infographic_result, dict):
        infographic_url = infographic_result.get("infographic_url") or infographic_result.get("{{infographic_url}}") or ""
        claude_usaget = infographic_result.get("claude_usaget") or infographic_result.get("{{claude_usaget}}") or 0
        claude_credit = infographic_result.get("claude_credit") or infographic_result.get("{{claude_credit}}") or ""

    chatgpt_usaget = int(_get(dr, "chatgpt_usaget", 0) or 0)
    chatgpt_credit = _get(dr, "chatgpt_credit", 0.0)

    print("\n========== Step6: ä¸­é–“ã‚µãƒãƒªï¼ˆãƒãƒ¼ãƒˆå¤‰æ•°ï¼‰ ==========")
    print(f"ğŸ§  ã‚¿ã‚¤ãƒˆãƒ« : {title}")
    print(f"ğŸ‘¤ è‘—è€…     : {author}")
    print(f"ğŸ·  ã‚«ãƒ†ã‚´ãƒª : {category}")
    print(f"ğŸ” research_url       : {research_url or '(ãªã—)'}")
    print(f"ğŸ–¼  infographic_path   : {inf_path or '(ãªã—)'}")
    print(f"ğŸŒ infographic_url    : {infographic_url or '(ãªã—)'}")
    print(f"ğŸ“£ æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸    : {(core_message[:120]+'...') if len(core_message)>120 else core_message or '(ç©º)'}")
    print(f"ğŸ–Š  ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–è¦ç´„  : {(executive_summary[:120]+'...') if len(executive_summary)>120 else executive_summary or '(ç©º)'}")
    print(f"ğŸ“š é–¢é€£æ›¸ç±            : {related_books or '(ç©º)'}")
    print(f"âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³           : 1){action_a or '(ç©º)'} / 2){action_b or '(ç©º)'} / 3){action_c or '(ç©º)'}")
    print(f"ğŸ§® chatgpt_usaget      : {chatgpt_usaget}")
    try:
        print(f"ğŸ’³ chatgpt_credit      : ${float(chatgpt_credit):.2f}")
    except Exception:
        print(f"ğŸ’³ chatgpt_credit      : {chatgpt_credit}")
    print(f"ğŸ§® claude_usaget       : {claude_usaget}")
    print(f"ğŸ’³ claude_credit       : {claude_credit or '(ä¸æ˜)'}")
    print("==============================================\n")

    # >>> PATCH: Fix YAML front matter for Books noteï¼ˆæ—¢å­˜ç¶­æŒï¼‰
    try:
        import re as _re, datetime as _dt
        from pathlib import Path as _P
        _vault = _P("/Users/seihoushouba/Documents/Oshomadesse-pc")
        _inbox = _vault / "100_Inbox"
        _today = _dt.datetime.now().strftime("%Y-%m-%d")
        _cands = sorted(_inbox.glob(f"Books-{_today}.md"), key=lambda p: p.stat().st_mtime, reverse=True)
        if not _cands:
            _cands = sorted(_inbox.glob("Books-*.md"), key=lambda p: p.stat().st_mtime, reverse=True)
        if _cands:
            _note = _cands[0]
            _txt  = _note.read_text(encoding="utf-8")
            _rest = _re.sub(r'^\ufeff?\s*---\s*\n.*?\n---\s*\n', '', _txt, flags=_re.S)
            _fixed = '---\n' + 'tags: [books]\n' + '---\n' + _rest.lstrip()
            if _fixed != _txt:
                _note.write_text(_fixed, encoding="utf-8")
                print(f"ğŸ©¹ Front matter fixed: {_note}")
    except Exception as _e:
        print(f"âš ï¸ front matter fix skipped: {_e!r}")
    # <<< PATCH END

    # >>> PATCH: persist remaining credits into .envï¼ˆæ—¢å­˜ç¶­æŒï¼‰
    try:
        import shutil, re, datetime as _dt2
        from pathlib import Path as _P
        _env_path = _P(__file__).resolve().parent / ".env"
        _lines = _env_path.read_text(encoding="utf-8").splitlines() if _env_path.exists() else []

        def _set_kv(_lines, _key, _val):
            _pat = re.compile(rf"^\s*{re.escape(_key)}\s*=")
            _out, _found = [], False
            for _ln in _lines:
                if _pat.match(_ln):
                    _out.append(f"{_key}={_val}"); _found = True
                else:
                    _out.append(_ln)
            if not _found:
                _out.append(f"{_key}={_val}")
            return _out

        def _to_float(x):
            try:
                s = str(x).strip()
                s = s.replace(",", "")
                if s.startswith("$"):
                    s = s[1:]
                return float(s)
            except Exception:
                return None

        _cg = _to_float(chatgpt_credit)
        _cl = _to_float(claude_credit if claude_credit not in (None, "(ä¸æ˜)") else "")

        _changed = False
        if _cg is not None:
            _lines = _set_kv(_lines, "CHATGPT_START_CREDIT", f"{_cg:.6f}"); _changed = True
        if _cl is not None:
            _lines = _set_kv(_lines, "CLAUDE_START_CREDIT", f"{_cl:.6f}"); _changed = True

        if _changed:
            _ts = _dt2.datetime.now().strftime("%Y%m%d_%H%M%S")
            if _env_path.exists():
                shutil.copyfile(str(_env_path), str(_env_path)+f".bak_{_ts}")
            _env_path.write_text("\n".join(_lines) + "\n", encoding="utf-8")
            print(f"ğŸ“ .env æ›´æ–°: CHATGPT_START_CREDIT={_cg if _cg is not None else '(nochange)'} / CLAUDE_START_CREDIT={_cl if _cl is not None else '(nochange)'} (path={_env_path})")
    except Exception as _e:
        print(f"âš ï¸ .envæ›´æ–°ã‚¹ã‚­ãƒƒãƒ—: {_e!r}")
    # <<< PATCH END

    return {
        "title": title,
        "author": author,
        "category": category,
        "research_url": research_url,
        "infographic_path": inf_path,
        "infographic_url": infographic_url,
        "core_message": core_message,
        "executive_summary": executive_summary,
        "related_books": related_books,
        "action_a": action_a, "action_b": action_b, "action_c": action_c,
        "chatgpt_usaget": chatgpt_usaget,
        "chatgpt_credit": chatgpt_credit,
        "claude_usaget": claude_usaget,
        "claude_credit": claude_credit,
    }
# ============ Step7: Obsidianãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆæŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å®Œå…¨æº–æ‹ ï¼‰ ============
def step7_save_to_obsidian_simple(mid_summary):
    """
    Step7: Step6ã§é›†ã‚ãŸå¤‰æ•°ã‚’ã€æŒ‡å®šã®ã€Œãƒãƒ¼ãƒˆæ§‹æˆã€ãƒ†ãƒ³ãƒ—ãƒ¬ã«æµã—è¾¼ã‚“ã§ 100_Inbox ã«ä¿å­˜ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«å: Books-YYYY-MM-DD.md
    """
    date_str = datetime.now().strftime("%Y-%m-%d")
    note_path = INBOX_DIR / f"Books-{date_str}.md"

    g = lambda k: (mid_summary.get(k) if isinstance(mid_summary, dict) else "")
    title = g("title") or ""
    author = g("author") or ""
    category = g("category") or ""
    infographic_url = g("infographic_url") or ""
    research_url = g("research_url") or ""
    action_a = g("action_a") or ""
    action_b = g("action_b") or ""
    action_c = g("action_c") or ""
    core_message = g("core_message") or ""
    executive_summary = g("executive_summary") or ""
    related_books = g("related_books") or ""
    chatgpt_usaget = g("chatgpt_usaget") or 0
    chatgpt_credit = g("chatgpt_credit") or 0
    claude_usaget = g("claude_usaget") or 0
    claude_credit = g("claude_credit") or ""

    # è¡¨ç¤ºç”¨ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆï¼ˆ$xx.xxï¼‰
    try:
        chatgpt_credit_display = f"${float(chatgpt_credit):.2f}"
    except Exception:
        chatgpt_credit_display = str(chatgpt_credit)
    claude_credit_display = (claude_credit or "").strip()
    if claude_credit_display and not claude_credit_display.startswith("$"):
        try:
            claude_credit_display = f"${float(claude_credit_display):.2f}"
        except Exception:
            pass

    # é–¢é€£æ›¸ç±ã‚’ç®‡æ¡æ›¸ãã¸æ­£è¦åŒ–ï¼ˆ" / " ã‚‚æ”¹è¡Œã‚‚ä¸¡å¯¾å¿œã€æ—¢å­˜ãƒã‚¤ãƒ•ãƒ³ã¯é‡è¤‡å›é¿ï¼‰
    def _to_bullets(s: str) -> str:
        raw = (s or "").strip()
        if not raw:
            return "- ãªã—"
        if "\n" in raw:
            parts = [ln.strip() for ln in raw.splitlines()]
        elif " / " in raw:
            parts = [p.strip() for p in raw.split(" / ")]
        else:
            parts = [raw]
        out_lines = []
        for p in parts:
            if not p:
                continue
            if p[0] in "-*â€¢ãƒ»":
                p = p[1:].lstrip()
            out_lines.append(f"- {p}")
        return "\n".join(out_lines)

    related_books_md = _to_bullets(related_books)

    # ãƒãƒ¼ãƒˆæœ¬æ–‡ï¼ˆæŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼šãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å³å®ˆã€ãƒªãƒ³ã‚¯åŒ–ã€1è¡Œã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ï¼‰
    content = f"""---
tags: [books]
---

## ã€ ğŸ§  {title} ã€‘

### ğŸ“š åŸºæœ¬æƒ…å ± 
- ğŸ‘¤ è‘—è€…:{author}
- ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªãƒ¼: [[{category}]]

### ğŸ¨ ç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„
- ğŸ–¼ï¸ ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯: [{title}]({infographic_url})
- ğŸ” ãƒªã‚µãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆ: [{title}]({research_url})

### âœ… ä»Šæ—¥ã§ãã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ 
- [ ] {action_a}
- [ ] {action_b}
- [ ] {action_c}
  
### ğŸ—£ï¸ è¦ç´„
- ğŸ“£ æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
```
{core_message}
```

- ğŸ–Šï¸ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒãƒªãƒ¼
```
{executive_summary}
```


### ğŸ“š é–¢é€£æ›¸ç±
{related_books_md}


""".rstrip() + "\n"

    try:
        note_path.write_text(content, encoding="utf-8")

        # >>> PATCH: Booksãƒãƒ¼ãƒˆã®ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’ Research ã¨åŒå½¢å¼ã§å¼·åˆ¶
        try:
            import re as _re, datetime as _dt
            from pathlib import Path as _P
            _vault = _P("/Users/seihoushouba/Documents/Oshomadesse-pc")
            _inbox = _vault / "100_Inbox"
            _today = _dt.datetime.now().strftime("%Y-%m-%d")
            # ç”Ÿæˆå¯¾è±¡ï¼ˆä»Šæ—¥ã® Books-YYYY-MM-DD.md ã‚’å„ªå…ˆã€ç„¡ã‘ã‚Œã°æœ€æ–°ã® Books-*.mdï¼‰
            _cands = sorted(_inbox.glob(f"Books-{_today}.md"), key=lambda q: q.stat().st_mtime, reverse=True)
            if not _cands:
                _cands = sorted((_inbox.glob("Books-*.md")), key=lambda q: q.stat().st_mtime, reverse=True)
            if _cands:
                _note = _cands[0]
                _txt  = _note.read_text(encoding="utf-8")
                # æ—¢å­˜ã®ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ï¼ˆ--- ... ---ï¼‰ã‚’å‰¥ãŒã™
                _body = _re.sub(r'^\ufeff?\s*---\s*\n.*?\n---\s*\n', '', _txt, flags=_re.S)
                # Research ã¨åŒã˜ã‚¹ã‚¿ã‚¤ãƒ«: è¡Œé…åˆ—â†’join ã§ç¢ºå®Ÿã«æ•´å½¢
                _head = ["---", "tags: [books]", "---"]
                _fixed = "\n".join(_head) + "\n" + _body.lstrip()
                if _fixed != _txt:
                    _note.write_text(_fixed, encoding="utf-8")
                    print(f"ğŸ©¹ Books front matter normalized -> {_note.name}")
        except Exception as _e:
            print(f"âš ï¸ Books front matter normalize skipped: {_e!r}")
        # <<< PATCH END
        print(f"âœ… Step7: ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº† -> {note_path}")
        return {"success": True, "saved_path": str(note_path)}
    except Exception as e:
        print("âŒ Step7: ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ:", e)
        return {"success": False, "error": str(e)}
# ============ Step8: link_books.py ã‚’å®Ÿè¡Œï¼ˆé€šçŸ¥å‰ã®ãƒ•ãƒƒã‚¯ï¼‰ ============
def step8_run_list_py(mid_summary=None):
    """
    Step8: link_books.py ã‚’å®Ÿè¡Œï¼ˆé€šçŸ¥å‰ã®ãƒ•ãƒƒã‚¯ï¼‰ã€‚
    """
    print("=========== Step8: link_books.py å®Ÿè¡Œ ===========")
    try:
        import subprocess, sys
        env = os.environ.copy()
        env["VAULT_ROOT"] = str(VAULT_ROOT)

        # éAIãƒ­ã‚¸ãƒƒã‚¯ã®ã¿ï¼ˆæ­£è¦è¡¨ç¾ãƒªãƒ³ã‚¯ï¼‰
        script1 = str(Path(PROJECT_DIR) / "link_books.py")
        r1 = subprocess.run([sys.executable, script1], env=env, capture_output=True, text=True)
        if (r1.stdout or "").strip():
            print((r1.stdout or "").strip())
        if r1.returncode != 0:
            print(f"âš ï¸ Step8: link_books.py returncode={r1.returncode}")
            if (r1.stderr or "").strip():
                print((r1.stderr or "").strip())
        else:
            print("âœ… Step8: link_books.py å®Ÿè¡Œ OK")

        return {
            "success": (r1.returncode == 0),
            "stdout": (r1.stdout or ""),
            "stderr": (r1.stderr or ""),
            "rc1": r1.returncode,
        }
    except Exception as e:
        print(f"âš ï¸ Step8: ä¾‹å¤–ç™ºç”Ÿ: {e}")
        return {"success": False, "error": str(e)}

# ============ Step9: é¸å®šã—ãŸæœ¬ã‚’é™¤å¤–æœ¬ãƒªã‚¹ãƒˆã«è¿½åŠ  ============
def step8_append_to_excluded_list(mid_summary):
    """
    Step9: Step8å®Œäº†å¾Œã€é¸å®šã—ãŸæœ¬ã‚’é™¤å¤–æœ¬ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½è¨˜ã™ã‚‹ã€‚
    A:D = [YYYY-MM-DD(ä»Šæ—¥), title, author, category]
    å€¤ã¯ Step6 ã® mid_summary ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆå¿…è¦æœ€å°é™ï¼‰ã€‚
    å„ªå…ˆé †:
      1) sheets_connector ã« appendç³»ãŒã‚ã‚Œã°ä½¿ç”¨
      2) EXCLUDED_APPEND_WEBHOOK ãŒã‚ã‚Œã° POST
      3) gspreadï¼ˆã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®šãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
    """
    print("=========== Step9: é™¤å¤–æœ¬ãƒªã‚¹ãƒˆã¸è¿½è¨˜ ===========")
    try:
        import json as _json

        # ä»Šæ—¥ï¼ˆAsia/Tokyoæƒ³å®šã€ä»–ã‚¹ãƒ†ãƒƒãƒ—ã¨åˆã‚ã›ã¦ naive nowï¼‰
        date_str = datetime.now().strftime("%Y-%m-%d")

        # Step6ã®ã‚µãƒãƒªã‚’ãã®ã¾ã¾åˆ©ç”¨
        g = (lambda k: (mid_summary.get(k) if isinstance(mid_summary, dict) else ""))  # æ—¢å­˜ã®æ›¸ãæ–¹ã«åˆã‚ã›ã‚‹
        title = str(g("title") or "").strip()
        author = str(g("author") or "").strip()
        category = str(g("category") or "").strip()

        # æœ€å°ã®æ•´å½¢ï¼ˆå¿…è¦æ€§ãŒé«˜ã„ã‚‚ã®ã®ã¿ï¼‰
        title = title.replace("ã€", "").replace("ã€‘", "").strip()
        category = category.replace("[[", "").replace("]]", "").strip()

        row = [date_str, title, author, category]
        print(f"ğŸ“ è¿½è¨˜è¡Œ: {row}")

        # 1) sheets_connector ãŒ appendç³»ã‚’æŒã£ã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
        if sheets_connector:
            for fn in ("append_excluded_row", "append_excluded_book", "append_excluded_books"):
                if hasattr(sheets_connector, fn):
                    try:
                        getattr(sheets_connector, fn)(row)
                        print(f"âœ… Step9: sheets_connector.{fn} ã§è¿½è¨˜ã«æˆåŠŸ")
                        return {"success": True, "method": f"sheets_connector.{fn}", "row": row}
                    except TypeError:
                        # (date,title,author,category) å½¢å¼ã®å¯èƒ½æ€§
                        try:
                            getattr(sheets_connector, fn)(date_str, title, author, category)
                            print(f"âœ… Step9: sheets_connector.{fn}(4args) ã§è¿½è¨˜ã«æˆåŠŸ")
                            return {"success": True, "method": f"sheets_connector.{fn}(4args)", "row": row}
                        except Exception as e:
                            print(f"âš  sheets_connector.{fn} å‘¼ã³å‡ºã—å¤±æ•—: {e}")
                    except Exception as e:
                        print(f"âš  sheets_connector.{fn} å¤±æ•—: {e}")

        # 2) Webhookï¼ˆApps Script ãªã©ï¼‰
        webhook = os.getenv("EXCLUDED_APPEND_WEBHOOK", "").strip()
        if webhook:
            try:
                try:
                    import requests
                    r = requests.post(webhook, json={"date": date_str, "title": title, "author": author, "category": category}, timeout=12)
                    ok = bool(getattr(r, "ok", False))
                    status = getattr(r, "status_code", None)
                    text = getattr(r, "text", "")
                except Exception:
                    import urllib.request, json as _j
                    req = urllib.request.Request(webhook, data=_j.dumps({"date": date_str, "title": title, "author": author, "category": category}).encode("utf-8"),
                                                 headers={"Content-Type":"application/json"}, method="POST")
                    with urllib.request.urlopen(req, timeout=12) as resp:
                        status = resp.getcode()
                        text = resp.read().decode("utf-8", "ignore")
                        ok = 200 <= status < 300
                if ok:
                    print("âœ… Step9: Webhook ã§è¿½è¨˜ã«æˆåŠŸ")
                    return {"success": True, "method": "webhook", "row": row, "status": status}
                else:
                    print(f"âš  Webhook å¿œç­”ã‚¨ãƒ©ãƒ¼: {status} {text[:200]}")
            except Exception as we:
                print(f"âš  Webhook é€ä¿¡ã«å¤±æ•—: {we}")

        # 3) gspread ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        try:
            import gspread
            from google.oauth2.service_account import Credentials as _Creds
            _SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
            # èªè¨¼ï¼ˆç’°å¢ƒå¤‰æ•°ã«å¿œã˜ã¦3é€šã‚Šï¼‰
            creds = None
            json_str = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()
            json_path = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON_PATH", "").strip()
            gac_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS", "").strip()

            if json_str:
                creds = _Creds.from_service_account_info(_json.loads(json_str), scopes=_SCOPES)
            elif json_path and os.path.exists(json_path):
                creds = _Creds.from_service_account_file(json_path, scopes=_SCOPES)
            elif gac_path and os.path.exists(gac_path):
                # GOOGLE_APPLICATION_CREDENTIALS ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’æ˜ç¤ºçš„ã«ä½¿ã†
                creds = _Creds.from_service_account_file(gac_path, scopes=_SCOPES)
            else:
                try:
                    import google.auth
                    creds, _ = google.auth.default(scopes=_SCOPES)
                except Exception:
                    creds = None

            if creds is None:
                raise RuntimeError("ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆGOOGLE_SERVICE_ACCOUNT_JSON / _PATH / GOOGLE_APPLICATION_CREDENTIALS ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰")

            SPREADSHEET_ID = os.getenv("EXCLUDED_SHEET_ID", "1aZ9VkAE3ZMfc6tkwfVPjolMZ4DU6SwodBUc2Yd13R10")
            SHEET_GID = int(os.getenv("EXCLUDED_SHEET_GID", "638408503"))

            gc = gspread.authorize(creds)
            sh = gc.open_by_key(SPREADSHEET_ID)
            ws = sh.get_worksheet_by_id(SHEET_GID)
            if ws is None:
                raise RuntimeError(f"gid={SHEET_GID} ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            ws.append_row(row, value_input_option="USER_ENTERED")
            print("âœ… Step9: gspread ã§è¿½è¨˜ã«æˆåŠŸ")
            return {"success": True, "method": "gspread", "row": row}
        except Exception as ge:
            print("âŒ Step9: gspread ã§ã®è¿½è¨˜ã«å¤±æ•—:", ge)
            return {"success": False, "error": str(ge), "row": row}

    except Exception as e:
        print("âŒ Step9: ä¾‹å¤–ç™ºç”Ÿ:", e)
        return {"success": False, "error": str(e)}
# ============ Step10: step10å®Œäº†é€šçŸ¥ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸é€ä¿¡ ============
import os, glob
from pathlib import Path as _Path
from urllib.parse import quote as _quote

def _build_obsidian_note_url(note_path: str) -> str:
    """
    Booksãƒãƒ¼ãƒˆã®çµ¶å¯¾ãƒ‘ã‚¹ â†’ obsidian://open?vault=...&file=... ã‚’è¿”ã™
    """
    # if os.getenv("GITHUB_ACTIONS"):
    #     # GitHub Actionsç’°å¢ƒã§ã¯GitHubã®ãƒªãƒã‚¸ãƒˆãƒªURLã‚’è¿”ã™ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
    #     repo = os.getenv("GITHUB_REPOSITORY", "oshomadesse/books-summary")
    #     # note_path ã¯çµ¶å¯¾ãƒ‘ã‚¹ãªã®ã§ã€ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’å–å¾—
    #     try:
    #         rel_path = _Path(note_path).relative_to(Path(PROJECT_DIR)).as_posix()
    #         # URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    #         rel_path_enc = _quote(rel_path)
    #         return f"https://github.com/{repo}/blob/main/{rel_path_enc}"
    #     except Exception:
    #         return f"https://github.com/{repo}"

    vault_root = _Path(os.getenv("VAULT_ROOT", "/Users/seihoushouba/Documents/Oshomadesse-pc")).resolve()
    vault_name = os.getenv("OBSIDIAN_VAULT_NAME", "Oshomadesse-main")
    note_abs = _Path(note_path).resolve()
    try:
        rel = note_abs.relative_to(vault_root).as_posix()
    except ValueError:
        # vault_rootå¤–ã«ã‚ã‚‹å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿
        rel = note_abs.name
    return f"obsidian://open?vault={_quote(vault_name)}&file={_quote(rel)}"

def _find_latest_books_note() -> str|None:
    """
    100_Inbox å†…ã® Books-*.md ã®ã†ã¡æœ€çµ‚æ›´æ–°ãŒæœ€æ–°ã®1ä»¶ã‚’è¿”ã™
    """
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã® INBOX_DIR ã‚’ä½¿ç”¨ã™ã‚‹ï¼ˆCIç’°å¢ƒã§ã¯ artifacts ã‚’æŒ‡ã—ã¦ã„ã‚‹ï¼‰
    inbox = INBOX_DIR
    files = glob.glob(str(_Path(inbox) / "Books-*.md"))
    if not files:
        return None
    return max(files, key=lambda p: _Path(p).stat().st_mtime)

def step9_send_notification_to_user(mid_summary=None):
    """
    Step10: Step9å®Œäº†å¾Œã«ã€LINE Messaging APIã§é€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹ã€‚
    Flex Messageå½¢å¼ï¼ˆnovelist-interviewæº–æ‹ ï¼‰ã§é€ä¿¡ã€‚
    """
    try:
        from line_messaging import line_push_text, line_push_flex
    except Exception as e:
        print(f"Step10: LINEé€šçŸ¥ã‚¹ã‚­ãƒƒãƒ—ï¼ˆline_messagingæœªå°å…¥ï¼‰: {e}")
        return

    note_path = _find_latest_books_note()
    if not note_path:
        print("Step10: Booksãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãšé€šçŸ¥ã‚¹ã‚­ãƒƒãƒ—")
        return

    url = _build_obsidian_note_url(note_path)
    
    # mid_summary ãŒãªã„å ´åˆã¯å¾“æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆé€šçŸ¥
    if not mid_summary:
        msg = f"ğŸ“š æœ¬æ—¥ã®èª­æ›¸æœ¬ã¯ã“ã¡ã‚‰ï¼\n{url}"
        r = line_push_text(msg)
        if not r.get("ok"):
            print(f"âŒ Step10: LINEé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {r}")
        else:
            print("âœ… Step10: LINEé€šçŸ¥é€ä¿¡ OK")
        return

    # Flex Message æ§‹ç¯‰
    title = mid_summary.get("title", "No Title")
    author = mid_summary.get("author", "")
    core_message = mid_summary.get("core_message", "")
    # æ ¸å¿ƒçš„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’çŸ­ãåˆ‡ã‚Šè©°ã‚ã‚‹
    if len(core_message) > 60:
        core_message = core_message[:60] + "..."
    
    # ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ãƒ‘ã‚¹ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ã—ã€GitHub Pagesã®URLã‚’æ§‹ç¯‰
    # path example: /home/runner/work/.../infographics/filename.html
    inf_path = mid_summary.get("infographic_path", "")
    infographic_pages_url = ""
    if inf_path:
        import os
        filename = os.path.basename(inf_path)
        # URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åå¯¾å¿œï¼‰
        from urllib.parse import quote
        filename_enc = quote(filename)
        # GitHub Pages URL: https://oshomadesse.github.io/books-summary/infographics/{filename}
        infographic_pages_url = f"https://oshomadesse.github.io/books-summary/infographics/{filename_enc}"

    # ãƒ’ãƒ¼ãƒ­ãƒ¼ç”»åƒ: å‰Šé™¤
    # hero_url = "https://via.placeholder.com/1024x500?text=Books+Summary"
    
    alt_text = f"ğŸ“š æœ¬æ—¥ã®èª­æ›¸ã‚µãƒãƒªãƒ¼: {title}"
    
    flex_obj = {
      "type": "bubble",
      "header": {
        "type": "box",
        "layout": "vertical",
        "contents": [
          {
            "type": "text",
            "text": "ğŸ“š æœ¬æ—¥ã®èª­æ›¸ã‚µãƒãƒªãƒ¼",
            "weight": "bold",
            "color": "#000000",
            "size": "sm"
          }
        ]
      },
      # hero ãƒ–ãƒ­ãƒƒã‚¯å‰Šé™¤
      "body": {
        "type": "box",
        "layout": "vertical",
        "contents": [
          {
            "type": "text",
            "text": title,
            "weight": "bold",
            "size": "xl",
            "wrap": True
          },
          {
            "type": "text",
            "text": author,
            "size": "sm",
            "color": "#666666",
            "wrap": True,
            "margin": "sm"
          },
          {
            "type": "text",
            "text": core_message,
            "size": "sm",
            "color": "#666666",
            "wrap": True,
            "margin": "md"
          }
        ]
      },
      "footer": {
        "type": "box",
        "layout": "vertical",
        "spacing": "sm",
        "contents": [
          {
            "type": "button",
            "style": "primary",
            "height": "sm",
            "action": {
              "type": "uri",
              "label": "å›³è§£ã‚’è¦‹ã‚‹",
              "uri": infographic_pages_url if infographic_pages_url else url
            }
          }
        ],
        "flex": 0
      }
    }
    
    # ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒœã‚¿ãƒ³è¿½åŠ ãƒ­ã‚¸ãƒƒã‚¯å‰Šé™¤

    r = line_push_flex(flex_obj, alt_text=alt_text)
    if not r.get("ok"):
        print(f"âŒ Step10: LINE Flexé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {r}")
    else:
        print("âœ… Step10: LINE Flexé€šçŸ¥é€ä¿¡ OK")


# ============ å®Ÿè¡Œåˆ¶å¾¡ ============
def run_until(step):
    usage_records = {}
    excl = step1_get_excluded_books()
    if step == 1:
        return
    recs = step2_generate_recommendations(excl, usage_records)
    if step == 2:
        return
    sel = step3_select_book(recs)
    if step == 3:
        return
    deep = step4_deep_research(sel, usage_records)
    if step == 4:
        return
    # â‘  Step4ã®å‡ºåŠ›ãŒè–„ã„ã¨ãï¼ˆ<=1000 charsï¼‰ã¯ã“ã“ã§åœæ­¢ã—ã¦ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆç¯€ç´„
    try:
        deep_len = len(str(deep.get("raw") or "")) if isinstance(deep, dict) else len(str(deep or ""))
    except Exception:
        deep_len = len(json.dumps(deep, ensure_ascii=False))
    print(f"â„¹ï¸ Deep Research length check (post-Step4): {deep_len} chars")
    if deep_len <= 1000:
        print("âš ï¸ Step4 Deep Research ãŒ 1000 chars ä»¥ä¸‹ã®ãŸã‚å‡¦ç†ã‚’åœæ­¢ã—ã¾ã™ï¼ˆStep5ä»¥é™ã¯å®Ÿè¡Œã—ã¾ã›ã‚“ï¼‰ã€‚")
        return

    infopath = step5_generate_infographic(deep, sel, usage_records)
    if step == 5:
        return
    mid = step6_mid_summary(sel, deep, infopath)
    if step == 6:
        return
    step7_save_to_obsidian_simple(mid)
    # Step7 ã®ç›´å¾Œã« Step8ï¼ˆlist.pyï¼‰ã‚’å®Ÿè¡Œ â†’ Step9ï¼ˆé™¤å¤–ãƒªã‚¹ãƒˆè¿½è¨˜ï¼‰
    step8_run_list_py(mid)
    step8_append_to_excluded_list(mid)

    step9_send_notification_to_user(mid)

    # è¨ˆæ¸¬çµ‚äº†: GitHub Actionsé–‹å§‹ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¡¨ç¤º
    start_ts = os.getenv("WORKFLOW_START_TIME")
    if start_ts and start_ts.isdigit():
        try:
            import time
            now_ts = int(time.time())
            diff = now_ts - int(start_ts)
            print(f"â±ï¸ Total duration from workflow start to final notification: {diff} seconds")
        except Exception as e:
            print(f"âš ï¸ Time measurement failed: {e}")
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--diag", action="store_true")
    parser.add_argument("--probe", action="store_true")
    parser.add_argument("--logfile", type=str, default=None)
    parser.add_argument("--until", type=int, default=10, help="æŒ‡å®šã‚¹ãƒ†ãƒƒãƒ—ã¾ã§å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10ï¼‰")
    args = parser.parse_args()
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    if not args.logfile:
        import datetime as dt
        today = dt.date.today().strftime("%Y%m%d")
        log_dir = os.path.join(PROJECT_DIR, "data", "integrated")
        os.makedirs(log_dir, exist_ok=True)
        args.logfile = os.path.join(log_dir, f"integrated_run_{today}.log")

    if args.logfile:
        os.environ["IRW_LOGFILE"] = args.logfile
        def _make_printer2(logfile):
            import builtins as _bi
            def _p(*a, **k):
                _bi.print(*a, **k)
                try:
                    with open(logfile, "a", encoding="utf-8") as fp:
                        _bi.print(*a, **k, file=fp)
                except Exception:
                    pass
            return _p
        globals()["print"] = _make_printer2(os.environ["IRW_LOGFILE"])
        print("Logging to: " + os.environ["IRW_LOGFILE"])
    if args.diag:
        try:
            step0_diag_env(probe=args.probe, model_hint=os.getenv("GPT5_MODEL","gpt-5"))
        except Exception as _e:
            print("è¨ºæ–­ã§ä¾‹å¤–: " + str(_e))
        sys.exit(0)
    try:
        run_until(args.until)
    except Exception as e:
        print("\nâŒ å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼")
        print("ç¨®é¡:", type(e).__name__)
        print("å†…å®¹:", e)
        traceback.print_exc()
